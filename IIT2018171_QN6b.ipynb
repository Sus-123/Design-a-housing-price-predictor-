{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IIT2018171_QN6b.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZU4cw1Lpdhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "fc6bc1bb-0fd2-4de6-d0df-51e81f4d6dfe"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# define functions\n",
        "\n",
        "def perform_Batch(X,y,alpha):\n",
        "    Xt = X.transpose()\n",
        "    m, n = np.shape(X)\n",
        "    theta = np.array([0,0,0,0])\n",
        "    for i in range(10000):\n",
        "        prediction = X.dot(theta)\n",
        "        difference = prediction - y\n",
        "\n",
        "        gradient = Xt.dot(difference) / m\n",
        "        theta = theta - alpha * gradient\n",
        "    return theta\n",
        "\n",
        "def perform_Stochastic(X,y,alpha) :\n",
        "    m, n = np.shape(X)\n",
        "    theta = np.array([0, 0, 0, 0])\n",
        "    for i in range(10000):\n",
        "        idx = np.random.randint(0, len(X) - 1)\n",
        "        X_chosen = np.array([X[idx]])\n",
        "        Y_chosen = np.array([y[idx]])\n",
        "        prediction = X_chosen.dot(theta)\n",
        "        difference = prediction - Y_chosen\n",
        "\n",
        "        gradient = X_chosen.transpose().dot(difference) / m\n",
        "        theta = theta - alpha * gradient\n",
        "    return theta\n",
        "\n",
        "def perform_mini_batch(X,y,alpha,batch_size):\n",
        "    m = len(y)\n",
        "    theta = np.array([0, 0, 0, 0])\n",
        "    batch_count = m / batch_size\n",
        "    for _ in range(10000):\n",
        "        indices = np.random.permutation(m)\n",
        "        X = X[indices]\n",
        "        Y = y[indices]\n",
        "        for i in range(0, m, batch_size):\n",
        "            X_chosen = X[i:i + batch_size]\n",
        "            Y_chosen = Y[i:i + batch_size]\n",
        "\n",
        "            prediction = X_chosen.dot(theta)\n",
        "            difference = prediction - Y_chosen\n",
        "\n",
        "            gradient = X_chosen.transpose().dot(difference) / m\n",
        "            theta = theta - alpha * gradient\n",
        "    return theta\n",
        "\n",
        "\n",
        "# pandas only for reading in the csv file\n",
        "data = pandas.read_csv(\"data.csv\")\n",
        "\n",
        "\n",
        "# our inputs, upon which price has to be predicted\n",
        "x1 = np.array(data['lotsize'])\n",
        "x2 = np.array(data['bedrooms'])\n",
        "x3 = np.array(data['bathrms'])\n",
        "\n",
        "\n",
        "y = np.array(data['price'])\n",
        "ones_ = np.ones((len(x1),1)) # the term associated with no inputs (no x's)\n",
        "n = len(x1)\n",
        "\n",
        "x1_new = x1.reshape(n,1)\n",
        "x2_new = x2.reshape(n,1)\n",
        "x3_new = x3.reshape(n,1)\n",
        "combined = np.append(ones_,x1_new,axis=1)\n",
        "combined = np.append(combined,x2_new,axis=1)\n",
        "combined = np.append(combined,x3_new,axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined, y, test_size = 0.3, random_state = 42)\n",
        "W = perform_mini_batch(X_train,y_train,0.00000005,10)\n",
        "print(W)\n",
        "x1_test = []\n",
        "x2_test = []\n",
        "x3_test = []\n",
        "for item in X_test:\n",
        "    x1_test.append(item[1]) # to avoid overflow\n",
        "    x2_test.append(item[2])\n",
        "    x3_test.append(item[3])\n",
        "\n",
        "x1_test = np.array(x1_test)\n",
        "x2_test = np.array(x2_test)\n",
        "x3_test = np.array(x3_test)\n",
        "\n",
        "\n",
        "\n",
        "calc = 0\n",
        "error = 0\n",
        "for i in range(len(X_test)) :\n",
        "    value = W[0] + W[1]*x1_test[i] + W[2]*x2_test[i] + W[3]*x3_test[i]\n",
        "    error += (abs(y_test[i] - value) / y_test[i])\n",
        "\n",
        "print('% error : ',error*100/len(X_test))\n",
        "\n",
        "\n",
        "## after feature resacling\n",
        "\n",
        "temp_list = []\n",
        "for item in X_train:\n",
        "    temp_list.append(item[1])\n",
        "\n",
        "dr = np.amax(temp_list) - np.amin(temp_list)\n",
        "mean_ = np.amin(temp_list)\n",
        "\n",
        "for item in X_train:\n",
        "    item[1] = (item[1] - mean_)/dr\n",
        "\n",
        "W = perform_mini_batch(X_train,y_train,0.05,10)\n",
        "\n",
        "\n",
        "#########\n",
        "temp_list = []\n",
        "for item in X_test:\n",
        "    temp_list.append(item[1])\n",
        "\n",
        "dr = np.amax(temp_list) - np.amin(temp_list)\n",
        "mean_ = np.amin(temp_list)\n",
        "\n",
        "for item in X_test:\n",
        "    item[1] = (item[1] - mean_)/dr\n",
        "\n",
        "x1_test = []\n",
        "x2_test = []\n",
        "x3_test = []\n",
        "for item in X_test:\n",
        "    x1_test.append(item[1]) # to avoid overflow\n",
        "    x2_test.append(item[2])\n",
        "    x3_test.append(item[3])\n",
        "\n",
        "x1_test = np.array(x1_test)\n",
        "x2_test = np.array(x2_test)\n",
        "x3_test = np.array(x3_test)\n",
        "\n",
        "calc = 0\n",
        "error = 0\n",
        "for i in range(len(X_test)) :\n",
        "    value = W[0] + W[1]*x1_test[i] + W[2]*x2_test[i] + W[3]*x3_test[i]\n",
        "    error += (abs(y_test[i] - value) / y_test[i])\n",
        "\n",
        "print('% error : ',error*100/len(X_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-efee87c4ab3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# pandas only for reading in the csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# our inputs, upon which price has to be predicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File data.csv does not exist: 'data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gFSjzwMras6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}